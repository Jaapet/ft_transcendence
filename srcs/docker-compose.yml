volumes:
  prometheus: {}
  elasticsearch_data: {}
  logstash_data: {}
  kibana_data: {}

services:
  proxy: #Reverse-proxy used to expose all web services to the client, reverse on subpath, run on Traefik v3
    build: ./requirements/proxy
    container_name: proxy_${PROJECT_NAME}
    image: proxy_${PROJECT_NAME} #TODO Remove before submiting
    profiles:
      - main
    command: #Startup traefik cmd to populate the static conf
      - "--log.level=INFO" #Mode dispo : RACE, DEBUG, INFO, WARN, ERROR, FATAL, and PANIC
      - "--api=true" # For Dashboard
      - "--api.insecure=false"
      - "--api.dashboard=true"
      - "--providers.docker=true" #Search in docker labels
      - "--providers.docker.exposedByDefault=false" #Do not expose every container, need the traefik.enable=true label
      - "--entrypoints.web.address=:80"
      - "--entrypoints.websecure.address=:443"
      - "--entrypoints.websocket.address=:4433"
      # - "--entrypoints.websecure.asDefault=true"
      #Smooth redirection http to https
      - "--entrypoints.web.http.redirections.entrypoint.to=websecure"
      - "--entrypoints.web.http.redirections.entrypoint.scheme=https"
      #Cert related dyn config
      - "--providers.file.filename=/app/ssl.yml"
      #Constraint to avoid multiple traefik conflicts (while dev stage)
      - "--providers.docker.constraints=Label(`my.zone`, `${PROJECT_NAME}`)"
      # Enable of prometheus metrics
      - "--metrics.prometheus=true"
      - "--metrics.prometheus.addEntryPointsLabels=true"
      - "--metrics.prometheus.addEntryPointsLabels=true"
      - "--metrics.prometheus.addServicesLabels=true"
    labels:
      - "my.zone=${PROJECT_NAME}"
      - "traefik.enable=true"
      # Basic Auth for /adm ressources
      - "traefik.http.middlewares.adm_auth.basicauth.users=${ADM_PASSWD}"
      # API & Dashboard
      - "traefik.http.routers.api.tls=true"
      - "traefik.http.routers.api.rule=(Host(`${FQDN}`) && PathPrefix(`/adm/traefik`) || HeaderRegexp(`Referer`, `.*/traefik/.*`))"
      - "traefik.http.routers.api.middlewares=adm_auth, traefik_stripe"
      - "traefik.http.middlewares.traefik_stripe.stripprefix.prefixes=/adm/traefik"
      - "traefik.http.routers.api.entrypoints=websecure"
      - "traefik.http.routers.api.service=api@internal"
      # Metrics configuration -- for prometheus
      - "traefik.http.routers.metrics.tls=true"
      - "traefik.http.routers.metrics.rule=Host(`proxy`) && PathPrefix(`/adm/metrics`)"
      - "traefik.http.routers.metrics.service=prometheus@internal"
      - "traefik.http.routers.api.entrypoints=websecure"
      - "traefik.http.routers.metrics.service=prometheus@internal"
    ports:
      # - "${PROJECT_PORT_ID}80:80" #Will be 80 when submiting
      - "${FRONT_PORT}:443" #Will be 443 when submiting
      - "${WEBSOCKET_PORT}:4433" #Will be 4433 when submiting
      # - "${PROJECT_PORT_ID}82:8080" #Will be 8080 when submiting, used for traefik dashboard
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock #Docker sock, should work in the school
    env_file:
      - .env
    depends_on:
      - frontend
    networks:
      default:
        aliases:
          - proxy #Used for inter containers communication, certs will match this fqdn
    #TODO HEALTHCHECK
    restart: unless-stopped

  db:
    build: ./requirements/db
    container_name: db_${PROJECT_NAME} #Don't change it, its important for certificates, db will receive the "db.cert"
    image: db_${PROJECT_NAME} #TODO Remove before submiting
    profiles:
      - main
    command: -c ssl=on -c ssl_cert_file=/ssl/db.crt -c ssl_key_file=/ssl/db.key
    env_file:
      - .env
    volumes: #Volumes binded should be changed before submiting the project
      - ./requirements/db/mount:/var/lib/postgresql/data
    networks:
      default:
        aliases:
          - db
    #TODO HEALTHCHECK
    restart: unless-stopped

  backend:
    build: ./requirements/backend
    container_name: backend_${PROJECT_NAME}  
    image: backend_${PROJECT_NAME} #TODO Remove before submiting
    profiles:
      - main
    ports: #Expose port should be removed, the only authorize entrypoint for the front && backend will be the front throught the proxy
      - "${BACK_PORT}:8000"
    env_file:
      - .env
    volumes: #TODO Volumes binded should be changed before submiting the project
      - ./requirements/backend/conf/mount:/usr/app
    depends_on:
      - db
    networks:
      default:
        aliases:
          - backend #Used for inter containers communication, certs will match this fqdn
      #TODO HEALTHCHECK
    restart: unless-stopped

  frontend:
    build: ./requirements/frontend
    container_name: frontend_${PROJECT_NAME}
    image: frontend_${PROJECT_NAME} #TODO Remove before submiting
    profiles:
      - main
    labels: #Label used to dynamically conf traefik
      - "my.zone=${PROJECT_NAME}"
      - "traefik.enable=true"

      # front
      - "traefik.http.routers.frontend.rule=Host(`${FQDN}`)"
      - "traefik.http.routers.frontend.tls=true"
      - "traefik.http.routers.frontend.entrypoints=websecure"
      - "traefik.http.services.frontend.loadbalancer.server.port=3000"
      - "traefik.http.routers.frontend.service=frontend@docker"

      # websockets
      - "traefik.http.routers.websocket.rule=Host(`${FQDN}`)"
      - "traefik.http.routers.websocket.tls=true"
      - "traefik.http.routers.websocket.entrypoints=websocket"
      - "traefik.http.services.websocket.loadbalancer.server.port=3001"
      - "traefik.http.routers.websocket.service=websocket@docker"
    env_file:
      - .env
    volumes: #TODO Volumes binded should be changed before submiting the project
      - ./requirements/frontend/conf/mount:/app/src
    depends_on:
      - backend
    networks:
      default:
        aliases:
          - frontend #Used for inter containers communication, certs will match this fqdn
    #TODO HEALTHCHECK
    deploy:
      resources:
        limits:
          memory: 512M
    restart: unless-stopped

##Monitoring
  prometheus: #Prometheus is the metric collector used by Grafana
    build: ./requirements/prometheus
    container_name: prometheus_${PROJECT_NAME}
    image: prometheus_${PROJECT_NAME} #TODO Remove before submiting
    profiles:
      - monitoring
    labels: #Label used to dynamically conf traefik
      - "my.zone=${PROJECT_NAME}"
      - "traefik.enable=true"
      - "traefik.http.routers.prometheus.tls=true"
      - "traefik.http.routers.prometheus.rule=Host(`${FQDN}`) && PathPrefix(`/adm/prometheus`)"
      - "traefik.http.routers.prometheus.entrypoints=websecure"
      - "traefik.http.services.prometheus.loadbalancer.server.port=9090"
      # TLS Proxy to service
      - "traefik.http.services.prometheus.loadbalancer.server.scheme=https" #Communicate with the service in HTTPS
      - "traefik.http.services.prometheus.loadbalancer.serverstransport=transport_prometheus@file"
      # Auth
        #Add a whitelist who only allow current ip (access from localhost) TODO WHEN SUBMITING
      - "traefik.http.routers.prometheus.middlewares=adm_auth"
    env_file:
      - .env
    volumes: #Volume not binded OK
      - prometheus:/prometheus
    depends_on:
      - backend
      - proxy
    networks:
      default:
        aliases:
          - prometheus #Used for inter containers communication, certs will match this fqdn
      #TODO HEALTHCHECK
    restart: unless-stopped
  
  grafana: #Grafana is a graph app useful for visualizing metrics
    build: ./requirements/grafana
    container_name: grafana_${PROJECT_NAME} #Don't change it, it's important for certificates, frontend will receive the "frontend.cert"
    image: grafana_${PROJECT_NAME}
    profiles:
      - monitoring
    labels: #Label used to dynamically conf traefik
      - "my.zone=${PROJECT_NAME}"
      - "traefik.enable=true"
      - "traefik.http.routers.grafana.tls=true"
      - "traefik.http.routers.grafana.rule=Host(`${FQDN}`) && PathPrefix(`/adm/grafana`)"
      - "traefik.http.routers.grafana.entrypoints=websecure"
      - "traefik.http.services.grafana.loadbalancer.server.port=3000"
      # TLS Proxy to service
      - "traefik.http.services.grafana.loadbalancer.server.scheme=https" #Communicate with the service in HTTPS
      - "traefik.http.services.grafana.loadbalancer.serverstransport=transport_grafana@file"
      # Auth
        #Add a whitelist who only allow current ip (access from localhost) TODO WHEN SUBMITING
      - "traefik.http.routers.grafana.middlewares=adm_auth"
    env_file:
      - .env
    networks:
      default:
        aliases:
          - grafana
    restart: unless-stopped

  postgres-exporter: #Postgres-Exporter is a service to create an interface between prostgre and prometheus
    build: ./requirements/postgres-exporter
    container_name: postgres-exporter_${PROJECT_NAME}
    image: postgres-exporter_${PROJECT_NAME}
    profiles:
      - monitoring
    env_file:
      - .env
    depends_on:
      - db
    networks:
      default:
        aliases:
          - postgres-exporter #Used for inter containers communication, certs will match this fqdn
      #TODO HEALTHCHECK
    restart: unless-stopped
##ELK
  elasticsearch:
    build: ./requirements/elasticsearch
    container_name: elasticsearch_${PROJECT_NAME}
    image: elasticsearch_${PROJECT_NAME}
    profiles:
      - elk
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data/
    env_file:
      - .env
    networks:
      default:
        aliases:
          - elasticsearch #Used for inter containers communication, certs will match this fqdn
    healthcheck: #Basic healtcheck that cat the API, if it respond the service is UP
      test: curl -s -X GET https://elasticsearch:9200 -u ${ELASTIC_USERNAME}:${ELASTIC_PASSWORD} > /dev/null || exit 1
      interval: 10s
      timeout: 3s
      retries: 30 #Increade this number if the server is a toaster, like the macs mini
    restart: unless-stopped

  logstash:
    build: ./requirements/logstash
    container_name: logstash_${PROJECT_NAME}
    image: logstash_${PROJECT_NAME}
    profiles:
      - elk
    volumes:
      - logstash_data:/usr/share/logstash/data
    networks:
      default:
        aliases:
          - logstash #Used for inter containers communication, certs will match this fqdn
    depends_on:
      elasticsearch:
        condition: service_healthy

    #TODO HEALTHCHECK
    restart: unless-stopped

  kibana:
    build: ./requirements/kibana
    container_name: kibana_${PROJECT_NAME}
    image: kibana_${PROJECT_NAME}
    profiles:
      - elk
    labels: #Label used to dynamically conf traefik
      - "my.zone=${PROJECT_NAME}"
      - "traefik.enable=true"
      - "traefik.http.routers.kibana.tls=true"
      - "traefik.http.routers.kibana.rule=Host(`${FQDN}`) && PathPrefix(`/adm/kibana`)"
      - "traefik.http.routers.kibana.entrypoints=websecure"
      - "traefik.http.services.kibana.loadbalancer.server.port=5601"
      # TLS Proxy to service
      - "traefik.http.services.kibana.loadbalancer.server.scheme=https" #Communicate with the service in HTTPS
      - "traefik.http.services.kibana.loadbalancer.serverstransport=transport_kibana@file"
      # Auth
      #Add a whitelist who only allow current ip (access from localhost) TODO WHEN SUBMITING
      # - "traefik.http.routers.kibana.middlewares=adm_auth" #Cannot use it it conflict with kibana legacy login
    env_file:
      - .env
    volumes:
      - kibana_data:/usr/share/kibana/data
    networks:
      default:
        aliases:
          - kibana #Used for inter containers communication, certs will match this fqdn
    depends_on:
      elasticsearch:
        condition: service_healthy
    #TODO HEALTHCHECK
    restart: unless-stopped